import os
import streamlit as st
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import re
from datetime import timedelta

# æ¨¡åž‹åˆå§‹åŒ–
@st.cache_resource
def load_model():
    # return SentenceTransformer('all-MiniLM-L6-v2')
    # return SentenceTransformer('paraphrase-multilingual-mpnet-base-v2')
    # return SentenceTransformer('intfloat/multilingual-e5-large')
    return SentenceTransformer('intfloat/e5-large-v2')
    # return SentenceTransformer('BAAI/bge-m3')



model = load_model()

def time_to_timedelta(t):
    h, m, s_ms = t.split(":")
    s, ms = s_ms.split(",")
    return timedelta(hours=int(h), minutes=int(m), seconds=int(s), milliseconds=int(ms))

def parse_srt(srt_content):
    pattern = re.compile(r"(\d+)\s+(\d{2}:\d{2}:\d{2},\d{3}) --> (\d{2}:\d{2}:\d{2},\d{3})\s+(.*?)\s+(?=\d+\s+\d{2}|\Z)", re.DOTALL)
    entries = []
    for match in pattern.finditer(srt_content):
        index = int(match.group(1))
        start = match.group(2)
        end = match.group(3)
        text = match.group(4).replace("\n", " ").strip()
        entries.append({"index": index, "start": start, "end": end, "text": text})
    return entries

def semantic_similarity(sent1, sent2, threshold=0.75):
    emb1 = model.encode([sent1])[0]
    emb2 = model.encode([sent2])[0]
    sim = cosine_similarity([emb1], [emb2])[0][0]
    print(f'\n\nsent1: "{sent1}"\nsent2: "{sent2}"\nsim: {sim}')
    return sim > threshold

def merge_entries(entries, time_gap_threshold=1.5, sim_threshold=0.75):
    merged = []
    buffer = [entries[0]]
    for curr in entries[1:]:
        prev = buffer[-1]
        prev_end = time_to_timedelta(prev["end"])
        curr_start = time_to_timedelta(curr["start"])
        gap = (curr_start - prev_end).total_seconds()
        similarity = semantic_similarity(prev["text"], curr["text"], sim_threshold)
        if gap < time_gap_threshold and similarity:
            buffer.append(curr)
        else:
            merged.append({
                "start": buffer[0]["start"],
                "end": buffer[-1]["end"],
                "text": " ".join([b["text"] for b in buffer])
            })
            buffer = [curr]
    if buffer:
        merged.append({
            "start": buffer[0]["start"],
            "end": buffer[-1]["end"],
            "text": " ".join([b["text"] for b in buffer])
        })
    for i, entry in enumerate(merged, 1):
        entry["index"] = i
    return merged

# â¬‡ï¸ ç¼“å­˜åˆå¹¶å¤„ç†é€»è¾‘ï¼Œåªè¦ slider å‚æ•°æˆ–å†…å®¹æ”¹å˜å°±é‡æ–°æ‰§è¡Œ
@st.cache_data(show_spinner="æ­£åœ¨åˆå¹¶å­—å¹•ä¸­...")
def get_merged_results(srt_text: str, sim_threshold: float, gap_threshold: float):
    entries = parse_srt(srt_text)
    merged = merge_entries(entries, time_gap_threshold=gap_threshold, sim_threshold=sim_threshold)
    # print('merged results: \n')
    # for i in merged:
    #     print(i)
    return entries, merged

st.title("ðŸŽ¬ SRT å¥å­æ™ºèƒ½åˆå¹¶å·¥å…·")

# â¬‡ï¸ æœ¬åœ° SRT è¯»å–ï¼ˆè°ƒè¯•ç”¨ï¼‰ï¼Œä½ ä¹Ÿå¯ä»¥ç”¨ä¸Šä¼ æ–¹å¼
srt_file_path = os.path.join(os.path.dirname(__file__), 'example.srt')
with open(srt_file_path, 'r') as f:
    srt_text = f.read()

# â¬‡ï¸ æŽ§åˆ¶æ»‘åŠ¨æ¡ï¼ˆè§¦å‘é‡æ–°è®¡ç®—ï¼‰
sim_threshold = st.slider("è¯­ä¹‰ç›¸ä¼¼åº¦é˜ˆå€¼", 0.5, 0.95, 0.75, 0.01)
gap_threshold = st.slider("æœ€å¤§æ—¶é—´é—´éš”ï¼ˆç§’ï¼‰", 0.1, 5.0, 1.5, 0.1)

# â¬‡ï¸ è‡ªåŠ¨é‡æ–°å¤„ç†
entries, merged = get_merged_results(srt_text, sim_threshold, gap_threshold)

# å±•ç¤º
st.subheader("åŽŸå§‹å­—å¹•ç‰‡æ®µ")
for e in entries[:10]:
    st.text(f"[{e['start']} â†’ {e['end']}] {e['text']}")

st.subheader("ðŸ” åˆå¹¶ç»“æžœ")
for e in merged[:10]:
    st.markdown(f"**[{e['start']} â†’ {e['end']}]** {e['text']}")

# ä¸‹è½½
st.download_button("ðŸ“¥ ä¸‹è½½åˆå¹¶åŽå­—å¹•", 
                   data="\n\n".join([f"{e['index']}\n{e['start']} --> {e['end']}\n{e['text']}" for e in merged]),
                   file_name="merged_output.srt",
                   mime="text/plain")
